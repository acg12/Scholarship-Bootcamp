{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommendation and Conclusion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3Zeqt7s4hz8yxd1IICdCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acg12/Scholarship-Bootcamp/blob/main/CASE_FINAL_PROJECT_ML/Recommendation_and_Conclusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-q-OiMsynt6"
      },
      "source": [
        "# Recommendation and Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__YoVivWyqwF"
      },
      "source": [
        "I tested several models, including models with gradient-boosting algorithms, like XGBoost, LightGBM, and CatBoost. In the end, I decided to go with CatBoost as it displayed the best results with a recall score of 0.67 on the validation data and 0.65 on the unseen data, which means the model is very stable, although not performing its best.\n",
        "\n",
        "The work I have done is unfinished though; there are still a lot more improvements to be made. These improvements were not made due to limited time on the project. The biggest improvement to be made is the performance of the final model. Although it is currently not that bad, but it is not good enough to be deployed yet."
      ]
    }
  ]
}